import numpy as np
import pandas as pd
import os
import logging
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import mutual_info_classif
from sklearn.decomposition import PCA

# ‚úÖ Initialize Logger
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# ‚úÖ Path to CICIDS 2017 dataset
DATA_FOLDER = "data/cicids_2017"

# ‚úÖ List all CSV files in the folder
file_paths = [os.path.join(DATA_FOLDER, file) for file in os.listdir(DATA_FOLDER) if file.endswith(".csv")]

# ‚úÖ Load & Merge All CSV Files
df_list = []
for file in file_paths:
    logger.info(f"üìÇ Loading {file}...")
    df_list.append(pd.read_csv(file, encoding="ISO-8859-1", low_memory=False))

df = pd.concat(df_list, ignore_index=True)
logger.info(f"‚úÖ Loaded {len(df):,} rows from CICIDS 2017 dataset.")

# ‚úÖ Take only 100,000 rows for quick testing
df = df.sample(n=100000, random_state=42)  
logger.info(f"‚úÖ Sampled {len(df):,} rows for testing.")

# ‚úÖ Remove spaces from column names
df.columns = df.columns.str.strip()

# ‚úÖ Fix special characters in attack labels
df["Label"] = df["Label"].str.replace("√Ø¬ø¬Ω", "-", regex=True)

# ‚úÖ Drop Unnecessary Columns
columns_to_drop = ["Flow ID", "Source IP", "Destination IP", "Timestamp"]
df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)

# ‚úÖ Convert 'Label' into Binary Classification
attack_labels = ["DoS Hulk", "PortScan", "DDoS", "DoS GoldenEye", "FTP-Patator",
                 "SSH-Patator", "DoS slowloris", "DoS Slowhttptest", "Bot",
                 "Web Attack - Brute Force", "Web Attack - XSS",
                 "Infiltration", "Web Attack - Sql Injection", "Heartbleed"]

df["is_malicious"] = df["Label"].apply(lambda x: 1 if x in attack_labels else 0)  # ‚úÖ Rename to `is_malicious`
df.drop(columns=["Label"], inplace=True)  # ‚úÖ Remove old column

logger.info("‚úÖ Attack labels converted to binary classification (1 = Attack, 0 = Normal).")

# ‚úÖ Convert all non-numeric columns to numeric
df = df.apply(pd.to_numeric, errors="coerce")

# ‚úÖ Handle Missing & Infinite Values
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.fillna(0, inplace=True)

# ‚úÖ Feature Selection using Mutual Information (MI)
logger.info("üîç Computing Mutual Information...")
X = df.drop(columns=["is_malicious"]).values
y = df["is_malicious"].values
mi_scores = mutual_info_classif(X, y, discrete_features=False, n_neighbors=3, random_state=42)

# ‚úÖ Select Top 27 Features (Ensure it Matches CNN Model)
top_n = 27
selected_features = np.argsort(mi_scores)[-top_n:]
X_selected = X[:, selected_features]
logger.info(f"‚úÖ Selected top {len(selected_features)} features.")

# ‚úÖ Standardization (Scaling)
logger.info("üîÑ Standardizing features...")
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_selected)

# ‚úÖ Save Scaler Mean & Scale for Future Use
np.save("data/scaler_mean.npy", scaler.mean_)
np.save("data/scaler_scale.npy", scaler.scale_)

# ‚úÖ Apply PCA (Reduce Dimensions to Match Training)
logger.info("üß† Applying PCA...")
pca = PCA(n_components=27, svd_solver='auto', random_state=42)
X_pca = pca.fit_transform(X_scaled)

# ‚úÖ Save Processed Data
df_processed = pd.DataFrame(X_pca, columns=[f"PC{i}" for i in range(1, 28)])
df_processed["is_malicious"] = y  # ‚úÖ Include `is_malicious`
df_processed.to_csv("data/processed_cicids.csv", index=False)

logger.info("‚úÖ Data saved: processed_cicids.csv")

# ‚úÖ Save PCA Explained Variance
np.save("data/pca_explained_variance.npy", pca.explained_variance_ratio_)
logger.info(f"üìä PCA Explained Variance: {sum(pca.explained_variance_ratio_) * 100:.2f}%")